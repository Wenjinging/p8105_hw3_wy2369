---
title: "p8105_hw3_wy2369"
output: github_document
author: "Wenjing Yang"
---

# Problem 1

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)

library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


### Load the dataset 

Using this code chunk to load data from `p8105.datasets`.

```{r}
data("instacart")

instacart = 
  instacart %>% 
  as_tibble(instacart)
```

### Write a short description of the dataset

This dataset contains **`r nrow(instacart)`** rows and **`r ncol(instacart)`** columns, with each row resprenting a single product from an instacart order. 

Variables include identifiers for user, order, and product; the order in which each product was added to the cart. There are several order-level variables, describing the day and time of the order, and number of days since prior order. Then there are several item-specific variables, describing the product name (e.g. Yogurt, Avocado), department (e.g. dairy and eggs, produce), and aisle (e.g. yogurt, fresh fruits), and whether the item has been ordered by this user in the past. 

In total, there are **`r instacart %>% select(product_id) %>% distinct %>% count`** products found in **`r instacart %>% select(user_id, order_id) %>% distinct %>% count`** orders from **`r instacart %>% select(user_id) %>% distinct %>% count`** distinct users.

Below is a table summarizing the number of items ordered from aisle. In total, there are **134** aisles, with fresh vegetables and fresh fruits holding the most items ordered by far.

```{r message = FALSE}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

### Make a plot the number of items ordered in each aisle

The plot shows the number of items ordered in each aisle, which n is more than 10000. Here, aisles are ordered by ascending number of items.

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```


### Make a table showing the three most popular items

The three most popular items in aisles are **`baking ingredients`**,**`dog food care`**, and **`packaged vegetables fruits`**, and the table includes the number of times each item is ordered.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

### Make a table showing the mean hour that Pink Lady Apples and Coffee Ice Cream are ordered

Finally is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. This table has been formatted in an untidy manner for human readers. 

Pink Lady Apples are generally purchased slightly earlier in the day than Coffee Ice Cream, with the exception of day 5.

```{r message = FALSE}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```



# Problem 2

### Load, tidy, and wrangle the data

The dataset includes all originally observed variables and values. It includes a weekday vs weekend variable (day_type) and encodes data with reasonable variable classes. 

```{r}
accel_df = 
  read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    day_type = if_else(day %in% c("Sunday","Saturday"),"weekend","weekday")) %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_interval",
    names_prefix = "activity_",
    values_to = "activity_count")%>%
    mutate(
      day = fct_relevel(day,c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"))) %>%
  arrange(week,day)

```

This resulting dataset contains **`r nrow(accel_df)`** rows and **`r ncol(accel_df)`** columns. There are 6 important variables which are **week**, **day_id**, **day**, **day_type**, **minute_interval**, and **activity_count**. 

From the dataset, I arrange the order of variable **day** to make sure people can easily find activity counts at certain day and certain time, which collected on a 63 year-old male with BMI 25.


### Analyse the data and create a table

Create a total activity variable for each day, and make a table showing these totals. 

```{r message = FALSE}
accel_total_activity = 
  accel_df %>%
  group_by(week,day) %>%
  summarize(total_activity = sum(activity_count))

accel_total_tidy =
  accel_total_activity %>%
  pivot_wider(
    names_from = day,
    values_from = total_activity)%>%
  knitr::kable()

accel_total_tidy
```

To find out the trend of these data, I also make a plot using the code chunk below.

```{r}
accel_total_activity %>%
  ggplot(aes(x= day, y = total_activity ,color= week)) +
  geom_point()+
  facet_grid(.~week)
```

From this plot, I think there is no obvious trend of total activity counts for each day. The highest total activity counts was collected on Monday of week 3, and the lowest was collected on Saturday of week 4 and week 5. 

### Make a single-panel plot that shows the 24-hour activity

Using this code chunk to make a plot which presents the 24-hour activity time courses for each day.

```{r}
accel_df %>%
  mutate(minute_interval = as.numeric(minute_interval))%>%
  ggplot(aes(x = minute_interval,y = activity_count, color = day, group = week))+
  geom_point()+
  labs(
    title = "24-hour activity count for each day",
    x = "time",
    y = "activity_count",
    caption = "Data from accel_data.csv"
  )+
  geom_line()+
    scale_x_continuous(
    breaks = c(180,360,540,720,900,1080,1260,1440),
    labels = c("3:00","6:00","9:00","12:00","15:00","18:00","21:00","24:00")
  )
```

Based on the resulting plot, the activity counts are always lower than 2500 from 22:00 to 5:00 for each day. However, activity counts increase at around 6:00, 9:00, 11:00, 16:00 and 20:00. From 20:00 to 22:00, most activity counts are higher than 5000 and the highest point is 8982. 

# Problem 3

### Load the data

```{r}
data("ny_noaa")
ny_noaa = 
  ny_noaa %>% 
  as_tibble(ny_noaa)
```

### Clean data and create separate variables

Clean data first, and create separate variables for **year**, **month**, and **day**. Using the code chunk below to convert variables **prcp**, **snow**, **snwd**, **tmax** and **tmin** into numeric variables. 

```{r}
ny_noaa_df = 
  ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c("year","month","day") ) %>%
  mutate(
    year = as.numeric(year),
    prcp = as.numeric(prcp)/10,
    snow = as.numeric(snow),
    snwd = as.numeric(snwd),
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10) 
```

Now there are **`r nrow(ny_noaa_df)`** rows and **`r ncol(ny_noaa_df)`** columns in the `ny_noaa_df` dataset. Variables are **`r ncol(ny_noaa_df)`** which include id, year, month, day, prcp(tenths of mm), snow(mm), snwd(mm), tmax(tenths of degrees C), and tmin(tenths of degrees C).   

### Find the most commonly observed value for snowfall

```{r}
ny_noaa_df %>%
  group_by(snow)%>%
  summarize(snow_obs = n())%>%
  arrange(desc(snow_obs))
```

For snowfall, the most commonly observed value is **0** which means for most day it is not snowing in NYC.   

### Make a two-panel plot showing the average max temperature in January and July

```{r message = FALSE}
ny_noaa_df%>%
  filter(month %in% c("01", "07")) %>%
  group_by(id, year, month) %>%
  drop_na(tmax) %>%
  summarize(mean_tmax = mean(tmax,na.rm = TRUE) ) %>%
  ggplot(aes(x = year,y = mean_tmax, color = month)) +
  geom_point()+
  labs(
    title = "The plot of average max temperature in January and July in each station across years",
    x = "year",
    y = "mean_tmax",
    caption = "Data from p8105. datasets") +
  facet_grid(.~month)
```

From the two-panel plot, the average max temperature in January are much lower than the average max temperature in July. The range of mean tmax in January is about (-10 ~ 10), but there are some outlines which are lower than -15 or higher than 10. The range of mean tmax in July is about (20 ~35), and there are also some outlines lower than 20. 

### Make a two-panel plot showing tmax vs tmin for the full dataset

Make a two-panel plot showing (i) tmax vs tmin for the full dataset (note that a scatterplot may not be the best option); and





(ii) make a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year.




